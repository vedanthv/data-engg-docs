## Databricks Control Plane and Data Plane

---

## ğŸš€ What is Databricks Lakehouse Architecture?

Traditionally, companies had **two separate systems**:

* **Data Lake** ğŸª£ (cheap storage, e.g., Azure Data Lake, S3, Blob): stores raw structured, semi-structured, unstructured data â†’ flexible but lacks strong data management (ACID, governance, BI).
* **Data Warehouse** ğŸ¢ (expensive but fast): optimized for SQL queries, BI, and analytics â†’ great schema enforcement and governance but limited flexibility and costly.

ğŸ”¹ The **Lakehouse** combines both in one system:

* The **low-cost, flexible storage** of a **data lake**
* The **governance, ACID transactions, performance** of a **warehouse**

---

## ğŸ—ï¸ Core Components of Databricks Lakehouse

1. **Storage Layer (Data Lake foundation)**

   * Data stored in **open formats** like Parquet, ORC, Avro, Delta.
   * Uses **cloud object storage** (e.g., Azure Data Lake Storage Gen2, AWS S3, GCS).

2. **Delta Lake (the secret sauce ğŸ§‚)**

   * Adds **ACID transactions** on top of data lake storage.
   * Provides **schema enforcement, schema evolution, time travel, data versioning**.
   * Solves problems like â€œeventual consistencyâ€ and corrupted files in raw data lakes.

3. **Unified Governance (Unity Catalog)**

   * Centralized **metadata & permissions** for files, tables, ML models, dashboards.
   * Manages security, lineage, and data discovery across the Lakehouse.

4. **Compute Layer (Databricks Runtime / Spark + Photon)**

   * Uses Apache Spark + Photon execution engine for **batch, streaming, ML, BI**.
   * Same engine for **ETL, streaming, AI, SQL queries** â†’ no silos.

5. **Data Management Features**

   * **Streaming + Batch = One Pipeline** (via Delta Live Tables).
   * **Materialized Views, Incremental Processing, Change Data Capture (CDC)**.
   * MLflow integration for **machine learning lifecycle management**.

---

## ğŸ“Š Architecture Diagram (Conceptual Flow)

```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Business Apps / BI  â”‚
                â”‚ (Power BI, Tableau)   â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Databricks SQL      â”‚
                â”‚   & Photon Engine     â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚          Delta Lake (ACID, Schema, CDC)       â”‚
   â”‚   (Open Storage Format on Parquet + Log)      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Cloud Object Store  â”‚
                â”‚ (ADLS, S3, GCS)       â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš¡ Benefits of Lakehouse

* âœ… **One platform** â†’ no need for separate warehouse + lake.
* âœ… **Cost efficient** â†’ cheap storage, scalable compute.
* âœ… **Flexibility** â†’ structured + semi-structured + unstructured.
* âœ… **ACID reliability** â†’ transactions, schema enforcement.
* âœ… **End-to-end** â†’ supports ETL, real-time streaming, ML/AI, BI in the same system.

---

## ğŸŒ In Databricks Azure Context

* Storage â†’ **Azure Data Lake Storage (ADLS Gen2)**
* Security/Governance â†’ **Azure Key Vault + Unity Catalog**
* Compute â†’ **Databricks Clusters with Photon**
* Serving â†’ **Power BI (Direct Lake Mode)**

---
## Data Plane vs Control Plane
---

# ğŸš¦ 1. Simple Analogy

Think of Databricks like **Uber**:

* **Control Plane = Uber App** ğŸ“± â†’ handles **where you go, who drives, billing, monitoring**.
* **Data Plane = The Car** ğŸš— â†’ where the **actual ride happens** (your data processing).

So, Databricks separates **management functions (control)** from **execution functions (data)**.

---

# ğŸ—ï¸ 2. Databricks Architecture

### ğŸ”¹ **Control Plane**

* Managed by **Databricks itself** (runs in Databricksâ€™ own AWS/Azure/GCP accounts).
* Contains:

  1. **Web UI / REST API** â†’ you log in here, create clusters, manage jobs.
  2. **Cluster Manager** â†’ decides how to spin up VMs/compute.
  3. **Job Scheduler** â†’ triggers pipelines, notebooks, workflows.
  4. **Metadata Storage** â†’ notebooks, workspace configs, Unity Catalog metadata.
  5. **Monitoring / Logging** â†’ cluster health, job logs, error reporting.

âš ï¸ **Important**: Your **raw data does not go here**. This plane is about orchestration, configs, and metadata.

---

### ğŸ”¹ **Data Plane**

* Runs inside **your cloud account** (your subscription/project).
* Contains:

  1. **Clusters/Compute** (Spark Executors, Driver, Photon) â†’ where the data is processed.
  2. **Your Data** â†’ stored in ADLS, S3, or GCS.
  3. **Networking** â†’ VNETs, Private Endpoints, Peering.
  4. **Libraries / Runtime** â†’ Spark, Delta Lake, MLflow, etc.

âš ï¸ **Key Point**: The **actual data never leaves your cloud account**. Processing happens within your boundary.

---

# ğŸ” 3. Security Perspective

* **Control Plane**:

  * Managed by Databricks.
  * Contains **metadata, credentials, configs**, but not raw data.
  * Can be hardened with **SCIM, SSO, RBAC, IP Access Lists**.

* **Data Plane**:

  * Fully inside **your cloud subscription**.
  * Your **sensitive data** (PII, transactions, crypto, etc.) never touches Databricksâ€™ account.
  * You control networking:

    * Private Link / VNET Injection â†’ ensures traffic never goes over the public internet.
    * Key Vault / KMS for secrets.
    * Storage firewalls.

---

# ğŸ–¼ï¸ 4. Architecture Diagram

```
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚           CONTROL PLANE              â”‚
               â”‚  (Databricks-managed account)        â”‚
               â”‚                                      â”‚
               â”‚  - Web UI / API                      â”‚
               â”‚  - Cluster Manager                   â”‚
               â”‚  - Job Scheduler                     â”‚
               â”‚  - Unity Catalog Metadata            â”‚
               â”‚  - Logs / Monitoring                 â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â”‚ Secure REST/API Calls
                               â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚             DATA PLANE                â”‚
               â”‚   (Your cloud subscription/project)   â”‚
               â”‚                                       â”‚
               â”‚  - Spark Driver & Executors           â”‚
               â”‚  - Photon Engine                      â”‚
               â”‚  - Data in ADLS/S3/GCS                â”‚
               â”‚  - Networking (VNET, Firewall, PEs)   â”‚
               â”‚  - Secrets from Key Vault/KMS         â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# âš¡ 5. Why This Separation?

âœ… **Security** â†’ Your data never leaves your account.
âœ… **Scalability** â†’ Databricks manages orchestration, you manage compute.
âœ… **Multi-cloud** â†’ Same control plane works across AWS, Azure, GCP.
âœ… **Compliance** â†’ Helps with HIPAA, GDPR, financial regulations.

---

# ğŸ”‘ 6. Special Feature: **Databricks Serverless SQL**

* Here, the **data plane compute is managed by Databricks** too (not your account).
* Good for quick BI queries (like Power BI), but some enterprises avoid it for sensitive data.

---
