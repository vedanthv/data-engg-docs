{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d6eeb0f-6bbe-47a6-9293-ddd8f3035f33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/15 16:23:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-20-231.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Reading Complex Data Formats</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7e6fd4181340>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"Reading Complex Data Formats\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3baf5a6b-6779-4de2-aed6-ff8291e7ec3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_parquet = spark.read.format(\"parquet\").load(\"data/sales_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e15ca92-8007-49cb-ba86-903c58644a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- transacted_at: timestamp (nullable = true)\n",
      " |-- trx_id: integer (nullable = true)\n",
      " |-- retailer_id: integer (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- city_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_parquet.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd359b9-fd43-46ea-9fda-92f1887b89d5",
   "metadata": {},
   "source": [
    "Parquet stores the metadata along with file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b29f6817-8100-4383-b2db-0d4b05af4d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+-----------+-----------------------------------------------+-------+----------+\n",
      "|transacted_at      |trx_id    |retailer_id|description                                    |amount |city_id   |\n",
      "+-------------------+----------+-----------+-----------------------------------------------+-------+----------+\n",
      "|2017-11-24 19:00:00|1995601912|2077350195 |Walgreen       11-25                           |197.23 |216510442 |\n",
      "|2017-11-24 19:00:00|1734117021|644879053  |unkn    ppd id: 768641     11-26               |8.58   |930259917 |\n",
      "|2017-11-24 19:00:00|1734117022|847200066  |Wal-Mart  ppd id: 555914     Algiers    11-26  |1737.26|1646415505|\n",
      "|2017-11-24 19:00:00|1734117030|1953761884 |Home Depot     ppd id: 265293   11-25          |384.5  |287177635 |\n",
      "|2017-11-24 19:00:00|1734117089|1898522855 |Target        11-25                            |66.33  |1855530529|\n",
      "|2017-11-24 19:00:00|1734117117|997626433  |Sears  ppd id: 856095  Ashgabat                |298.87 |957346984 |\n",
      "|2017-11-24 19:00:00|1734117123|1953761884 |unkn   ppd id: 153174    Little Rock    11-25  |19.55  |45522086  |\n",
      "|2017-11-24 19:00:00|1734117152|1429095612 |Ikea     arc id: 527956  Saint John's   11-26  |9.39   |1268541279|\n",
      "|2017-11-24 19:00:00|1734117153|847200066  |unkn        Kingstown                          |2907.57|1483931123|\n",
      "|2017-11-24 19:00:00|1734117212|1996661856 |unkn    ppd id: 454437   11-24                 |140.38 |336763936 |\n",
      "|2017-11-24 19:00:00|1734117241|486576507  |iTunes                                         |2912.67|1663872965|\n",
      "|2017-11-24 19:00:00|2076947148|847200066  |Wal-Mart         11-24                         |62.83  |1556600840|\n",
      "|2017-11-24 19:00:00|2076947147|562903918  |McDonald's    ccd id: 135878  Ljubljana   11-24|31.37  |930259917 |\n",
      "|2017-11-24 19:00:00|2076947146|511877722  |unkn     ccd id: 598521     Ankara   11-26     |1915.35|1698762556|\n",
      "|2017-11-24 19:00:00|2076947113|1996661856 |AutoZone  arc id: 998454    11-25              |1523.6 |1759612211|\n",
      "|2017-11-24 19:00:00|2076947018|902350112  |DineEquity    arc id: 1075293                  |22.28  |2130657559|\n",
      "|2017-11-24 19:00:00|2076946994|1898522855 |Target    ppd id: 336785                       |2589.93|2074005445|\n",
      "|2017-11-24 19:00:00|2076946985|847200066  |Wal-Mart    ppd id: 252763  11-26              |42.2   |459344513 |\n",
      "|2017-11-24 19:00:00|2076946960|386167994  |Wendy's  ppd id: 881511     11-24              |14.62  |352952442 |\n",
      "|2017-11-24 19:00:00|2076946954|486576507  |iTunes     ppd id: 121397                      |37.42  |485114748 |\n",
      "+-------------------+----------+-----------+-----------------------------------------------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_parquet.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54db6366-b76b-4fa0-b5a7-93f56bcd2d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orc = spark.read.format(\"orc\").load(\"data/sales_data.orc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73c7fa1d-1fb3-4ff1-8be4-c90961650193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benefits of Columnar Storage\n",
    "\n",
    "# Lets create a simple Python decorator - {get_time} to get the execution timings\n",
    "# If you dont know about Python decorators - check out : https://www.geeksforgeeks.org/decorators-in-python/\n",
    "import time\n",
    "\n",
    "def get_time(func):\n",
    "    def inner_get_time() -> str:\n",
    "        start_time = time.time()\n",
    "        func()\n",
    "        end_time = time.time()\n",
    "        return (f\"Execution time: {(end_time - start_time)*1000} ms\")\n",
    "    print(inner_get_time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb771638-a352-4621-9ea0-e38c7ee6f288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 791.6536331176758 ms\n"
     ]
    }
   ],
   "source": [
    "@get_time\n",
    "def x():\n",
    "    df = spark.read.format(\"parquet\").load(\"data/sales_data.parquet\")\n",
    "    df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6f06f15-fdf3-4c31-a9e2-ac8fc524dd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 255.80644607543945 ms\n"
     ]
    }
   ],
   "source": [
    "@get_time\n",
    "def x():\n",
    "    df = spark.read.format(\"parquet\").load(\"data/sales_data.parquet\")\n",
    "    df.select(\"trx_id\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd780aab-3e1f-43e7-8838-cf4ae4db675c",
   "metadata": {},
   "source": [
    "Observe that the time to read when we give just one column is significantly less"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ee7ab9-ca72-4e09-accf-39f4c060ec3d",
   "metadata": {},
   "source": [
    "# BONUS TIP\n",
    "# RECURSIVE READ\n",
    "\n",
    "```\n",
    "sales_recursive\n",
    "\n",
    "|__ sales_1\\1.parquet\n",
    "\n",
    "|__ sales_1\\sales_2\\2.parquet\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fa4eb5-eda9-4e11-b9f6-499b060fa940",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = spark.read.format(\"parquet\").option(\"recursiveFileLookup\", True).load(\"data/input/sales_recursive/\")\n",
    "df_1.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
